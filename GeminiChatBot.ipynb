{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCFCDTdlfOqW4Nbk/f5kWM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidoji1/infera-ai/blob/main/GeminiChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmVZ90BwG_vD",
        "outputId": "00eca1e4-c6d1-483d-b899-0aa0ad99559d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.26.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q flask flask-cors google-generativeai streamlit pyngrok\n",
        "!npm install -g localtunnel > /dev/null\n",
        "!pip install -q gTTS\n",
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDlJ1BPv0Di3QDZPG9DRgCe0rXU57TOmFc\""
      ],
      "metadata": {
        "id": "WUIJ81KyCBJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Correct way to read from env if set earlier\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "try:\n",
        "    model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")\n",
        "    chat_session = model.start_chat()\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Model initialization error:\", e)\n",
        "\n",
        "@app.route(\"/chat\", methods=[\"POST\"])\n",
        "def chat():\n",
        "    try:\n",
        "        user_input = request.json.get(\"message\", \"\")\n",
        "        if not user_input:\n",
        "            return jsonify({\"response\": \"‚ùó Empty message\"}), 400\n",
        "        response = chat_session.send_message(user_input)\n",
        "        return jsonify({\"response\": response.text})\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Chat error:\", e)\n",
        "        return jsonify({\"response\": f\"‚ùå Error: {e}\"}), 500\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"‚úÖ Using gemini-2.0-flash on port 5000\")\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7_hHm8vHdft",
        "outputId": "a3f9b4fd-e1b3-416d-aadf-3c93a9d60e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"2yOkor8VoMjF777K4kTxGg8txV3_5udNXMZjLXZykbXs1uum9\")  # your ngrok token\n",
        "\n",
        "# Start Flask server\n",
        "def run_flask():\n",
        "    subprocess.run([\"python3\", \"app.py\"])\n",
        "\n",
        "flask_thread = threading.Thread(target=run_flask)\n",
        "flask_thread.start()\n",
        "\n",
        "# Start new tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"üîó Flask URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK3qebYBOZVD",
        "outputId": "c906a416-f541-463c-d78d-52cb50eaec0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîó Flask URL: NgrokTunnel: \"https://903d-35-204-37-5.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = f\"https://903d-35-204-37-5.ngrok-free.app/chat\"\n",
        "payload = {\"message\": \"Hello Gemini\"}\n",
        "res = requests.post(url, json=payload)\n",
        "\n",
        "print(\"Status Code:\", res.status_code)\n",
        "print(\"Response:\", res.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejTBZObXEYn",
        "outputId": "b83bd5d5-ff4b-4154-ec55-9b66e5ef259a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Response: {\"response\":\"Hello! How can I help you today?\\n\"}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as frontend.py\n",
        "%%writefile frontend.py\n",
        "import streamlit as st\n",
        "import requests\n",
        "from gtts import gTTS\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# Set page config\n",
        "if os.path.exists(\"App_Icon.jpeg\"):\n",
        "    icon = Image.open(\"App_Icon.jpeg\")\n",
        "    st.set_page_config(page_title=\"Infera AI\", page_icon=icon, layout=\"wide\")\n",
        "else:\n",
        "    st.set_page_config(page_title=\"Infera AI\", layout=\"wide\")\n",
        "\n",
        "# Theme session state\n",
        "if \"theme\" not in st.session_state:\n",
        "    st.session_state.theme = \"dark\"\n",
        "\n",
        "if \"last_input\" not in st.session_state:\n",
        "    st.session_state.last_input = \"\"\n",
        "\n",
        "if \"last_response\" not in st.session_state:\n",
        "    st.session_state.last_response = \"\"\n",
        "\n",
        "# Sidebar\n",
        "with st.sidebar:\n",
        "    st.title(\"‚öôÔ∏è Settings\")\n",
        "    theme_toggle = st.toggle(\"üåó Toggle Light/Dark Mode\", value=(st.session_state.theme == \"dark\"))\n",
        "    st.session_state.theme = \"dark\" if theme_toggle else \"light\"\n",
        "\n",
        "    # Tone selector\n",
        "    st.markdown(\"üé≠ **Response Tone**\")\n",
        "    tone = st.selectbox(\"Choose a tone for replies\", [\"Default\", \"Friendly\", \"Professional\", \"Funny\", \"Sarcastic\"])\n",
        "\n",
        "    # TTS Language\n",
        "    languages = {\n",
        "        \"English\": \"en\",\n",
        "        \"Hindi\": \"hi\",\n",
        "        \"Kannada\": \"kn\",\n",
        "        \"Tamil\": \"ta\",\n",
        "        \"Telugu\": \"te\"\n",
        "    }\n",
        "    selected_lang = st.selectbox(\"üó£Ô∏è Choose TTS Language\", list(languages.keys()))\n",
        "    lang_code = languages[selected_lang]\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    if st.button(\"üìÑ Download Chat History\"):\n",
        "        chat_lines = [f\"{m['role'].capitalize()}: {m['content']}\" for m in st.session_state.get(\"chat_history\", [])]\n",
        "        chat_str = \"\\n\\n\".join(chat_lines)\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".txt\", mode='w', encoding='utf-8') as tmp:\n",
        "            tmp.write(chat_str)\n",
        "            st.download_button(\"üì• Save as .txt\", data=chat_str, file_name=\"chat_history.txt\", mime=\"text/plain\")\n",
        "\n",
        "    st.caption(\"üöÄ Built with ‚ù§Ô∏è using Streamlit + Gemini Flash\")\n",
        "\n",
        "# Theme colors\n",
        "dark_mode = st.session_state.theme == \"dark\"\n",
        "bg_color = \"#1e1e1e\" if dark_mode else \"#ffffff\"\n",
        "text_color = \"#ffffff\" if dark_mode else \"#000000\"\n",
        "user_bg = \"#2c3e50\" if dark_mode else \"#e3f2fd\"\n",
        "bot_bg = \"#34495e\" if dark_mode else \"#f1f8e9\"\n",
        "input_bg = \"#2c2c2c\" if dark_mode else \"#ffffff\"\n",
        "\n",
        "# Custom CSS\n",
        "st.markdown(f\"\"\"\n",
        "    <style>\n",
        "        .stApp {{\n",
        "            background-color: {bg_color};\n",
        "            color: {text_color};\n",
        "        }}\n",
        "        .chat-box {{\n",
        "            padding: 1rem;\n",
        "            border-radius: 12px;\n",
        "            margin: 10px 0;\n",
        "        }}\n",
        "        .user {{\n",
        "            background-color: {user_bg};\n",
        "        }}\n",
        "        .bot {{\n",
        "            background-color: {bot_bg};\n",
        "        }}\n",
        "        .stTextInput > div > input {{\n",
        "            background-color: {input_bg};\n",
        "            color: {text_color};\n",
        "        }}\n",
        "        .stButton button {{\n",
        "            background-color: #3b82f6;\n",
        "            color: white;\n",
        "            padding: 0.4rem 1rem;\n",
        "            border-radius: 6px;\n",
        "        }}\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Title\n",
        "st.markdown(f\"<h1 style='text-align: center; color: {text_color};'>ü§ñ Infera AI</h1>\", unsafe_allow_html=True)\n",
        "st.markdown(f\"<p style = 'text-align: center; font-size: 18px; color: {text_color}; font-style: italic;'>‚ú® Smarter Chat Deeper Insight</p>\", unsafe_allow_html=True)\n",
        "\n",
        "# Chat history\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "# Display chat history\n",
        "for chat in st.session_state.chat_history:\n",
        "    css_class = \"user\" if chat[\"role\"] == \"user\" else \"bot\"\n",
        "    icon = \"üßë\" if chat[\"role\"] == \"user\" else \"ü§ñ\"\n",
        "    st.markdown(f\"<div class='chat-box {css_class}'><b>{icon} {chat['role'].capitalize()}:</b><br>{chat['content']}</div>\", unsafe_allow_html=True)\n",
        "    if chat[\"role\"] == \"bot\":\n",
        "        try:\n",
        "            tts = gTTS(chat[\"content\"], lang=lang_code)\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp:\n",
        "                tts.save(tmp.name)\n",
        "                st.audio(tmp.name)\n",
        "        except Exception as e:\n",
        "            st.warning(f\"TTS failed: {e}\")\n",
        "\n",
        "# Input form\n",
        "with st.form(\"chat_form\", clear_on_submit=True):\n",
        "    cols = st.columns([9, 1])\n",
        "    user_input = cols[0].text_input(\"Type your message\", placeholder=\"Ask me anything...\", label_visibility=\"collapsed\")\n",
        "    send_btn = cols[1].form_submit_button(\"üì§\")\n",
        "\n",
        "# Handle input\n",
        "if send_btn and user_input.strip():\n",
        "    st.session_state.last_input = user_input\n",
        "    tone_prefix = \"\" if tone == \"Default\" else f\"Respond in a {tone.lower()} tone: \"\n",
        "    final_prompt = f\"{tone_prefix}{user_input}\"\n",
        "\n",
        "    st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    with st.spinner(\"Infera is thinking...\"):\n",
        "        try:\n",
        "            res = requests.post(\"https://903d-35-204-37-5.ngrok-free.app/chat\", json={\"message\": final_prompt})\n",
        "            bot_reply = res.json().get(\"response\", \"‚ö†Ô∏è No response from Gemini.\")\n",
        "        except Exception as e:\n",
        "            bot_reply = f\"‚ùå Error: {e}\"\n",
        "        st.session_state.last_response = bot_reply\n",
        "        st.session_state.chat_history.append({\"role\": \"bot\", \"content\": bot_reply})\n",
        "    st.rerun()\n",
        "\n",
        "# Regenerate Button\n",
        "if st.session_state.last_input:\n",
        "    if st.button(\"‚ôªÔ∏è Regenerate Last Reply\"):\n",
        "        st.session_state.chat_history.pop()  # remove last bot message\n",
        "        with st.spinner(\"Regenerating...\"):\n",
        "            try:\n",
        "                tone_prefix = \"\" if tone == \"Default\" else f\"Respond in a {tone.lower()} tone: \"\n",
        "                final_prompt = f\"{tone_prefix}{st.session_state.last_input}\"\n",
        "                res = requests.post(\"https://903d-35-204-37-5.ngrok-free.app/chat\", json={\"message\": final_prompt})\n",
        "                new_reply = res.json().get(\"response\", \"‚ö†Ô∏è No response from Gemini.\")\n",
        "            except Exception as e:\n",
        "                new_reply = f\"‚ùå Error: {e}\"\n",
        "            st.session_state.last_response = new_reply\n",
        "            st.session_state.chat_history.append({\"role\": \"bot\", \"content\": new_reply})\n",
        "        st.rerun()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2qdO_lsU_Vu",
        "outputId": "81900739-361e-49b3-f9d3-217544ada3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting frontend.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run frontend.py &> /dev/null &\n",
        "streamlit_url = ngrok.connect(8501)\n",
        "print(\"üîó Streamlit URL:\", streamlit_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqG26V8bedAc",
        "outputId": "89a5fe54-285c-4a35-b503-289324107bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîó Streamlit URL: NgrokTunnel: \"https://a707-35-204-37-5.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to kill the port and tunnel\n",
        "!fuser -k 5000/tcp\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()  # Kills all ngrok tunnels"
      ],
      "metadata": {
        "id": "-1gKDJJuUYkT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}